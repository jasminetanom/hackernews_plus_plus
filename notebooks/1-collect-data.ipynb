{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PostgreSQL database and table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"bq_all\"\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE {}(\n",
    "    id integer PRIMARY KEY,\n",
    "    author text,\n",
    "    title text,\n",
    "    score integer,\n",
    "    story_time timestamp,\n",
    "    url text,\n",
    "    commenters text,\n",
    "    all_text text\n",
    ")\n",
    "\"\"\".format(table_name))\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and export BigQuery table to Google Cloud Storage as .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/Users/jasminetan/Desktop/jt-dsi-capstone-5c0b7ccac053.json\"\n",
    "\n",
    "project = \"jt-dsi-capstone\"\n",
    "dataset_id = 'hacker_news'\n",
    "table_id = 'all'\n",
    "bucket_name = 'jt-dsi-capstone'\n",
    "file_name = 'all.csv*'\n",
    "\n",
    "query_str = \"\"\"\n",
    "SELECT\n",
    "  c.id,\n",
    "  c.author,\n",
    "  c.title,\n",
    "  c.score,\n",
    "  c.story_time,\n",
    "  c.url,\n",
    "  CONCAT(c.author, ', ', c.commenters, ', ') AS commenters,\n",
    "  CONCAT(c.title, '. ', c.story_text, '. ', c.comments) AS all_text\n",
    "FROM (\n",
    "  SELECT\n",
    "    ANY_VALUE(b.id) AS id,\n",
    "    ANY_VALUE(b.author) AS author,\n",
    "    ANY_VALUE(b.title) AS title,\n",
    "    ANY_VALUE(b.score) AS score,\n",
    "    ANY_VALUE(b.story_time) AS story_time,\n",
    "    ANY_VALUE(b.url) AS url,\n",
    "    ANY_VALUE(b.story_text) AS story_text,\n",
    "    STRING_AGG(DISTINCT commenter, ', ') AS commenters,\n",
    "    STRING_AGG(DISTINCT comment, '. ') AS comments\n",
    "  FROM ((\n",
    "      SELECT\n",
    "        DISTINCT a.id,\n",
    "        a.author,\n",
    "        a.title,\n",
    "        a.score,\n",
    "        a.story_time,\n",
    "        a.url,\n",
    "        a.story_text,\n",
    "        a.commenter1 AS commenter,\n",
    "        a.comment1 AS comment\n",
    "      FROM (\n",
    "        SELECT\n",
    "          s.id,\n",
    "          s.author,\n",
    "          s.title,\n",
    "          s.score,\n",
    "          s.story_time,\n",
    "          s.url,\n",
    "          s.text AS story_text,\n",
    "          p2.commenter AS commenter1,\n",
    "          p2.text AS comment1,\n",
    "          p1.commenter AS commenter2,\n",
    "          p1.text AS comment2,\n",
    "          p0.commenter AS commenter3,\n",
    "          p0.text AS comment3\n",
    "        FROM (\n",
    "          SELECT\n",
    "            id,\n",
    "            `by` AS commenter,\n",
    "            text,\n",
    "            parent\n",
    "          FROM\n",
    "            `bigquery-public-data.hacker_news.full`\n",
    "          WHERE\n",
    "            type LIKE 'comment') p0\n",
    "        JOIN (\n",
    "          SELECT\n",
    "            id,\n",
    "            `by` AS commenter,\n",
    "            text,\n",
    "            parent\n",
    "          FROM\n",
    "            `bigquery-public-data.hacker_news.full`\n",
    "          WHERE\n",
    "            type LIKE 'comment') p1\n",
    "        ON\n",
    "          p1.id=p0.parent\n",
    "        JOIN (\n",
    "          SELECT\n",
    "            id,\n",
    "            `by` AS commenter,\n",
    "            text,\n",
    "            parent\n",
    "          FROM\n",
    "            `bigquery-public-data.hacker_news.full`\n",
    "          WHERE\n",
    "            type LIKE 'comment') p2\n",
    "        ON\n",
    "          p2.id=p1.parent\n",
    "        JOIN (\n",
    "          SELECT\n",
    "            id,\n",
    "            `by` AS author,\n",
    "            score,\n",
    "            `timestamp` AS story_time,\n",
    "            url,\n",
    "            text,\n",
    "            title\n",
    "          FROM\n",
    "            `bigquery-public-data.hacker_news.full`\n",
    "          WHERE\n",
    "            type LIKE 'story'\n",
    "            AND score > 10\n",
    "            AND `timestamp` > '2011-12-31 23:59:00') s\n",
    "        ON\n",
    "          s.id=p2.parent) a)\n",
    "    UNION ALL (\n",
    "      SELECT\n",
    "        DISTINCT a.id,\n",
    "        a.author,\n",
    "        a.title,\n",
    "        a.score,\n",
    "        a.story_time,\n",
    "        a.url,\n",
    "        a.story_text,\n",
    "        a.commenter2 AS commenter,\n",
    "        a.comment2 AS comment\n",
    "      FROM (\n",
    "        SELECT\n",
    "          s.id,\n",
    "          s.author,\n",
    "          s.title,\n",
    "          s.score,\n",
    "          s.story_time,\n",
    "          s.url,\n",
    "          s.text AS story_text,\n",
    "          p2.commenter AS commenter1,\n",
    "          p2.text AS comment1,\n",
    "          p1.commenter AS commenter2,\n",
    "          p1.text AS comment2,\n",
    "          p0.commenter AS commenter3,\n",
    "          p0.text AS comment3\n",
    "        FROM (\n",
    "          SELECT\n",
    "            id,\n",
    "            `by` AS commenter,\n",
    "            text,\n",
    "            parent\n",
    "          FROM\n",
    "            `bigquery-public-data.hacker_news.full`\n",
    "          WHERE\n",
    "            type LIKE 'comment') p0\n",
    "        JOIN (\n",
    "          SELECT\n",
    "            id,\n",
    "            `by` AS commenter,\n",
    "            text,\n",
    "            parent\n",
    "          FROM\n",
    "            `bigquery-public-data.hacker_news.full`\n",
    "          WHERE\n",
    "            type LIKE 'comment') p1\n",
    "        ON\n",
    "          p1.id=p0.parent\n",
    "        JOIN (\n",
    "          SELECT\n",
    "            id,\n",
    "            `by` AS commenter,\n",
    "            text,\n",
    "            parent\n",
    "          FROM\n",
    "            `bigquery-public-data.hacker_news.full`\n",
    "          WHERE\n",
    "            type LIKE 'comment') p2\n",
    "        ON\n",
    "          p2.id=p1.parent\n",
    "        JOIN (\n",
    "          SELECT\n",
    "            id,\n",
    "            `by` AS author,\n",
    "            score,\n",
    "            `timestamp` AS story_time,\n",
    "            url,\n",
    "            text,\n",
    "            title\n",
    "          FROM\n",
    "            `bigquery-public-data.hacker_news.full`\n",
    "          WHERE\n",
    "            type LIKE 'story'\n",
    "            AND score > 10\n",
    "            AND `timestamp` > '2011-12-31 23:59:00') s\n",
    "        ON\n",
    "          s.id=p2.parent) a)\n",
    "    UNION ALL (\n",
    "      SELECT\n",
    "        DISTINCT a.id,\n",
    "        a.author,\n",
    "        a.title,\n",
    "        a.score,\n",
    "        a.story_time,\n",
    "        a.url,\n",
    "        a.story_text,\n",
    "        a.commenter3 AS commenter,\n",
    "        a.comment3 AS comment\n",
    "      FROM (\n",
    "        SELECT\n",
    "          s.id,\n",
    "          s.author,\n",
    "          s.title,\n",
    "          s.score,\n",
    "          s.story_time,\n",
    "          s.url,\n",
    "          s.text AS story_text,\n",
    "          p2.commenter AS commenter1,\n",
    "          p2.text AS comment1,\n",
    "          p1.commenter AS commenter2,\n",
    "          p1.text AS comment2,\n",
    "          p0.commenter AS commenter3,\n",
    "          p0.text AS comment3\n",
    "        FROM (\n",
    "          SELECT\n",
    "            id,\n",
    "            `by` AS commenter,\n",
    "            text,\n",
    "            parent\n",
    "          FROM\n",
    "            `bigquery-public-data.hacker_news.full`\n",
    "          WHERE\n",
    "            type LIKE 'comment') p0\n",
    "        JOIN (\n",
    "          SELECT\n",
    "            id,\n",
    "            `by` AS commenter,\n",
    "            text,\n",
    "            parent\n",
    "          FROM\n",
    "            `bigquery-public-data.hacker_news.full`\n",
    "          WHERE\n",
    "            type LIKE 'comment') p1\n",
    "        ON\n",
    "          p1.id=p0.parent\n",
    "        JOIN (\n",
    "          SELECT\n",
    "            id,\n",
    "            `by` AS commenter,\n",
    "            text,\n",
    "            parent\n",
    "          FROM\n",
    "            `bigquery-public-data.hacker_news.full`\n",
    "          WHERE\n",
    "            type LIKE 'comment') p2\n",
    "        ON\n",
    "          p2.id=p1.parent\n",
    "        JOIN (\n",
    "          SELECT\n",
    "            id,\n",
    "            `by` AS author,\n",
    "            score,\n",
    "            `timestamp` AS story_time,\n",
    "            url,\n",
    "            text,\n",
    "            title\n",
    "          FROM\n",
    "            `bigquery-public-data.hacker_news.full`\n",
    "          WHERE\n",
    "            type LIKE 'story'\n",
    "            AND score > 10\n",
    "            AND `timestamp` > '2011-12-31 23:59:00') s\n",
    "        ON\n",
    "          s.id=p2.parent) a)) b\n",
    "  GROUP BY\n",
    "    b.id) c\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query finished\n"
     ]
    }
   ],
   "source": [
    "bq_client = bigquery.Client()\n",
    "\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "\n",
    "# Set the destination table. Here, dataset_id is a string, such as:\n",
    "table_ref = bq_client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "job_config.use_legacy_sql = False\n",
    "job_config.location = 'US'\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "\n",
    "# The write_disposition specifies the behavior when writing query results\n",
    "# to a table that already exists. With WRITE_TRUNCATE, any existing rows\n",
    "# in the table are overwritten by the query results.\n",
    "# job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "\n",
    "# Start the query, passing in the extra configuration.\n",
    "query_job = bq_client.query(\n",
    "    query_str,\n",
    "    # Location must match that of the dataset(s) referenced in the query\n",
    "    # and of the destination table.\n",
    "    job_config=job_config)  # API request - starts the query\n",
    "\n",
    "query_job.result()\n",
    "print(\"Query finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported jt-dsi-capstone:hacker_news.all to gs://jt-dsi-capstone/all.csv*\n"
     ]
    }
   ],
   "source": [
    "destination_uri = 'gs://{}/{}'.format(bucket_name, file_name)\n",
    "dataset_ref = bq_client.dataset(dataset_id, project=project)\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "\n",
    "extract_job = bq_client.extract_table(\n",
    "    table_ref,\n",
    "    destination_uri,\n",
    "    # Location must match that of the source table.\n",
    "    location='US')  # API request\n",
    "extract_job.result()  # Waits for job to complete.\n",
    "\n",
    "print('Exported {}:{}.{} to {}'.format(\n",
    "    project, dataset_id, table_id, destination_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read .csv files and store in PostgreSQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "blobs = bucket.list_blobs(prefix=\"all.csv\")\n",
    "\n",
    "blobs_list = [blob for blob in blobs]\n",
    "\n",
    "file_indices = []\n",
    "\n",
    "for index, each_blob in enumerate(blobs_list):\n",
    "    each_blob.download_to_filename('all_{}.csv'.format(index))\n",
    "    file_indices.append(index)\n",
    "    print('all_{}.csv downloaded'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_0.csv loaded into bq_all\n",
      "all_1.csv loaded into bq_all\n",
      "all_2.csv loaded into bq_all\n",
      "all_3.csv loaded into bq_all\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "for index in file_indices:\n",
    "    with open('all_{}.csv'.format(index), 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip the header row.\n",
    "        for row in reader:\n",
    "            cur.execute(\n",
    "                \"INSERT INTO {} VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\".format(table_name),\n",
    "                row\n",
    "            )\n",
    "    conn.commit()\n",
    "    print('all_{}.csv loaded into {}'.format(index, table_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
